{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day1_Basics.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOs+DuwiiIea9S+/VlCL8XR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yongguang-Zhang/MiCroDential_2022/blob/master/Day1_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7fAnxyi7UkqO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30ca5eec-a08a-4f9d-fdd9-5be525d07edf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jan  3 18:30:16 2022       n+-----------------------------------------------------------------------------+n| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |n|-------------------------------+----------------------+----------------------+n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |n|                               |                      |               MIG M. |n|===============================+======================+======================|n|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |n| N/A   33C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |n|                               |                      |                  N/A |n+-------------------------------+----------------------+----------------------+n                                                                               n+-----------------------------------------------------------------------------+n| Processes:                                                                  |n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |n|        ID   ID                                                   Usage      |n|=============================================================================|n|  No running processes found                                                 |n+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = 'n'.join(gpu_info)\n",
        "if gpu_info.find('failed')>=0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import this"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kv8fy8JcWuwX",
        "outputId": "2d9b7453-15ac-4235-a47c-660e2944e888"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Zen of Python, by Tim Peters\n",
            "\n",
            "Beautiful is better than ugly.\n",
            "Explicit is better than implicit.\n",
            "Simple is better than complex.\n",
            "Complex is better than complicated.\n",
            "Flat is better than nested.\n",
            "Sparse is better than dense.\n",
            "Readability counts.\n",
            "Special cases aren't special enough to break the rules.\n",
            "Although practicality beats purity.\n",
            "Errors should never pass silently.\n",
            "Unless explicitly silenced.\n",
            "In the face of ambiguity, refuse the temptation to guess.\n",
            "There should be one-- and preferably only one --obvious way to do it.\n",
            "Although that way may not be obvious at first unless you're Dutch.\n",
            "Now is better than never.\n",
            "Although never is often better than *right* now.\n",
            "If the implementation is hard to explain, it's a bad idea.\n",
            "If the implementation is easy to explain, it may be a good idea.\n",
            "Namespaces are one honking great idea -- let's do more of those!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Hello 2022!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGWMHsX0QUCh",
        "outputId": "2ca5c04b-d16e-46ea-c636-583093d95eab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello 2022!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PYiesBlYQqNq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}